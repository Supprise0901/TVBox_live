import requests
import re
from bs4 import BeautifulSoup
import os
import threading
import mer_urls
import sys
import time


def get_url(name):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36"
    }
    url = "http://tonkiang.us/"
    # è·å–ä¸¤é¡µçš„m3u8é“¾æ¥
    # params = {
    #     "page": 1,
    #     "s": name
    # }
    # response = requests.get(url, headers=headers, params=params, verify=False)
    data = {
        "search": name,
        "Submit": " "
    }
    with requests.Session() as session:
        response = session.post(url, headers=headers, data=data, verify=False)
        print(response)
    # print(response.text)
    soup = BeautifulSoup(response.text, 'html.parser')
    # Find the div with class "m3u8"
    m3u8_divs = soup.find_all('div', class_='m3u8')
    m3u8_list = []
    for div in m3u8_divs:
        # Extract the HTTP link from the onclick attribute
        onclick_value = div.find('img')['onclick']
        url_match = re.search(r'copyto\("([^"]+)"\)', onclick_value)

        if url_match:
            extracted_url = url_match.group(1)
            print(extracted_url)
            m3u8_list.append(extracted_url)
        # else:
        #     print("URL extraction failed.")
    return m3u8_list


def validate_m3u8_url(url, name):
    try:
        # å‘é€HTTPè¯·æ±‚è·å–M3U8æ–‡ä»¶å†…å®¹
        with requests.get(url, timeout=10) as response:
            response.raise_for_status()
            if response.status_code == 200:
                valid_m3u8_link.append(url)
                print(f"{url}\n{name}M3U8é“¾æ¥æœ‰æ•ˆ")
                return url

    # except requests as e:
    except requests.exceptions.RequestException as e:
        result = f"{url}\nError: {name} æ— æ•ˆé“¾æ¥. Exception: {e}"
        print(result)
        return result
    except Exception as e:
        # å¤„ç†å…¶ä»–å¼‚å¸¸ï¼Œä¾‹å¦‚è¶…æ—¶
        result = f"{url}\nError: {name} å…¶ä»–å¼‚å¸¸. Exception: {e}"
        print(result)
        return result


# æ£€æµ‹æœ‰æ•ˆé“¾æ¥ï¼Œå¹¶å†™å…¥m3u8_url.txt
def detectLinks(name, m3u8_list, TV_name):
    thread = []
    for m3u8_url in m3u8_list:
        t = threading.Thread(target=validate_m3u8_url, args=(m3u8_url, name,))
        t.setDaemon(True)  # è®¾ç½®ä¸ºå®ˆæŠ¤çº¿ç¨‹,ç¡®ä¿åœ¨ä¸»çº¿ç¨‹é€€å‡ºæ—¶ï¼Œæ‰€æœ‰å­çº¿ç¨‹éƒ½ä¼šè¢«å¼ºåˆ¶ç»ˆæ­¢
        t.start()
        thread.append(t)
    # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
    for t in thread:
        try:
            print(f"Waiting for thread {t} to finish")
            t.join(timeout=5)  # ç­‰å¾…çº¿ç¨‹è¶…æ—¶
        except Exception as e:
            print(f"Thread {t} raised an exception: {e}")
    # æ£€æµ‹çš„valid_m3u8_linkåˆ—è¡¨ï¼Œä¿å­˜åˆ°m3u8_url.txtæ–‡æœ¬ä¸­
    time.sleep(10)
    # åˆ¤æ–­TV_namesåˆ—è¡¨ä¸­çš„æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(f'{TV_name}'):
        os.makedirs(f'{TV_name}')
    with open(os.path.join(f'{TV_name}', f'{name}.txt'), 'w', encoding='utf-8') as file:
        for valid_url in valid_m3u8_link:
            file.write(f'{name},{valid_url}\n')
        valid_m3u8_link.clear()
        sys.stdout.flush()


if __name__ == '__main__':
    # è·å–å½“å‰å·¥ä½œç›®å½•
    current_directory = os.getcwd()
    # æ„é€ ä¸Šçº§ç›®å½•çš„è·¯å¾„
    parent_dir = os.path.dirname(current_directory)
    output_file_path = os.path.join(parent_dir, 'live.txt')
    # æ¸…ç©ºlive.txtå†…å®¹
    with open(output_file_path, 'w', encoding='utf-8') as f:
        pass
    tv_dict = {}
    valid_m3u8_link = []
    # éå†å½“å‰æ–‡ä»¶ä¸‹çš„txtæ–‡ä»¶,æå–æ–‡ä»¶å
    TV_names = [os.path.splitext(f)[0] for f in os.listdir(current_directory) if f.endswith(".txt")]
    # TV_names = ['ğŸ‡­ğŸ‡°æ¸¯å°']
    for TV_name in TV_names:
        # è¯»å–æ–‡ä»¶å¹¶é€è¡Œå¤„ç†
        with open(f'{TV_name}.txt', 'r', encoding='utf-8') as file:
            names = [line.strip() for line in file]
            for name in names:
                m3u8_list = get_url(name)
                tv_dict[name] = m3u8_list
                print(name)
            print('---------å­—å…¸åŠ è½½å®Œæˆï¼------------')
        for name, m3u8_list in tv_dict.items():
            detectLinks(name, m3u8_list, TV_name)
        # åˆå¹¶m3u8é“¾æ¥
        mer_urls.mer_links(TV_name)
        tv_dict.clear()
